{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-Means - Unsupervised Learning with Python</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Refrance:</h2>\n",
    "\n",
    "https://towardsdatascience.com/unsupervised-learning-with-python-173c51dc7f03\n",
    "\n",
    "https://towardsdatascience.com/k-means-clustering-from-a-to-z-f6242a314e9a\n",
    "\n",
    "https://www.coursera.org/lecture/machine-learning/k-means-algorithm-93VPG\n",
    "\n",
    "https://towardsdatascience.com/want-clusters-how-many-will-you-have-8737f4ba9bf2\n",
    "<br>training with Javascript:<br>\n",
    "https://towardsdatascience.com/extracting-colours-from-an-image-using-k-means-clustering-9616348712be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Important Terminology</b></h4><br>\n",
    "<b>Feature:</b> An input variable used in making predictions.<br>\n",
    "<b>Predictions:</b> A model’s output when provided with an input example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The Concept:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most commonly used clustering method is K-Means (because of it’s simplicity).<br>\n",
    "The K in K-Means denotes the number of clusters. <br>\n",
    "This algorithm is bound to converge to a solution after some iterations. It has 4 basic steps:\n",
    "1. Initialize Cluster Centroids (Choose those 3 books to start with)\n",
    "2. Assign datapoints to Clusters (Place remaining the books one by one)<br>\n",
    "(according to Euclidean distance)\n",
    "3. Update Cluster centroids (Start over with 3 different books)\n",
    "4. Repeat step 2–3 until the stopping condition is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "picture:\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*xkuet4YVglp8KWsK90bfRw.gif\"></img>\n",
    "https://towardsdatascience.com/k-means-clustering-from-a-to-z-f6242a314e9a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>centroid:</b><br>\n",
    "As a starting point, you tell your model how many clusters it should make. First the model picks up K, (let K = 3) datapoints from the dataset. These datapoints are called cluster centroids.<br>\n",
    "- updated cluster centorid is the the mean value of all the datapoints within that cluster.\n",
    "-  instead of taking the average value, can take mode and median would be taken respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since step 2 and 3 would be performed iteratively, it would go on forever if we don’t set a stopping criterion. <br>\n",
    "It is important to note that setting a stopping criterion would not necessarily return THE BEST clusters,but to make sure it returns reasonably good clusters, and more importantly at least return some clusters, we need to have a stopping criterion.<br>\n",
    "When it is stopping:<br>(when happen one of the things below)\n",
    "1. The datapoints assigned to specific cluster remain the same (takes too much time)\n",
    "2. Centroids remain the same (time consuming)\n",
    "3. The distance of datapoints from their centroid is minimum (the thresh you’ve set)\n",
    "4. Fixed number of iterations have reached (insufficient iterations → poor results, choose max iteration wisely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article we use, Iris dataset for making our very first predictions. The dataset contains a set of 150 records under 5 attributes.<br>\n",
    "( Petal Length , Petal Width , Sepal Length , Sepal width and Class. Iris Setosa, Iris Virginica and Iris Versicolor are the three classes.)<br>\n",
    "For our Unsupervised Algorithm we give these four features of the Iris flower and predict which class it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "iris_df = datasets.load_iris()\n",
    "\n",
    "# Available methods on dataset\n",
    "print(dir(iris_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "print(iris_df.feature_names)\n",
    "\n",
    "# Targets\n",
    "print(iris_df.target)\n",
    "\n",
    "# Target Names\n",
    "print(iris_df.target_names)\n",
    "label = {0: 'red', 1: 'blue', 2: 'green'}\n",
    "\n",
    "# Dataset Slicing\n",
    "x_axis = iris_df.data[:, 0]  # Sepal Length\n",
    "y_axis = iris_df.data[:, 2]  # Sepal Width\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(x_axis, y_axis, c=iris_df.target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Clustering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>K-Means Clustering in Python:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means is an iterative clustering algorithm that aims to find local maxima in each iteration.<br>\n",
    "Initially desired number of clusters are chosen. Since we know that there are 3 classes involved, <br>\n",
    "we program the algorithm to group the data into 3 classes, by passing the parameter “n_clusters” into our KMeans model. <br>\n",
    "Now randomly three points(inputs) are assigned into three cluster. Based on the centroid distance between each points the next given inputs are segregated into respected clusters. <br>\n",
    "Now, re-computing the centroids for all the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "iris_df = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Model\n",
    "model = KMeans(n_clusters=3)\n",
    "\n",
    "# Fitting Model\n",
    "model.fit(iris_df.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicitng a single input\n",
    "predicted_label = model.predict([[7.2, 3.5, 0.8, 1.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the entire data\n",
    "all_predictions = model.predict(iris_df.data)\n",
    "\n",
    "# Printing Predictions\n",
    "print(predicted_label)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluating the cluster quality</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality clustering is when the datapoints within a cluster are close together, and afar from other clusters.<br>\n",
    "The two methods to measure the cluster quality are described below:\n",
    "1. <b>Inertia:</b><br> Intuitively, inertia tells how far away the points within a cluster are. Therefore, a small of inertia is aimed for. The range of inertia’s value starts from zero and goes up.\n",
    "2. <b>Silhouette score:</b><br>\n",
    "Silhouette score tells how far away the datapoints in one cluster are, from the datapoints in another cluster. The range of silhouette score is from -1 to 1. Score should be closer to 1 than -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>k-means optimization opertion :</h3>\n",
    "https://www.coursera.org/lecture/machine-learning/optimization-objective-G6QWt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c(i) = index of cluster(1,2,...,k) to which example x(i) ic currently assigned.<br>\n",
    "u(k) = cluster centriod k.<br>\n",
    "u(c,i)= cluster centriod of cluster to which example x(i) has been assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/whos-talking-using-k-means-clustering-to-sort-neural-events-in-python-e7a8a76f316\n",
    "<br>\n",
    "Another more objective way is to use the Elbow method. For this we run the K-means function several times on our data and increase the number of clusters with every run. For each run we calculate the average distance of each data point to its cluster center.  As the plot below shows, with the number of clusters increasing the average inter cluster distance decreases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum number of clusters to test\n",
    "max_num_clusters = 15\n",
    "# Run K-means with increasing number of clusters (20 times each)\n",
    "average_distance = []\n",
    "for run in range(20):\n",
    "    tmp_average_distance = []\n",
    "    for num_clus in range(1, max_num_clusters +1):\n",
    "        cluster, centers, distance = k_means(pca_result, num_clus)\n",
    "        tmp_average_distance.append(np.mean([np.mean(distance[x]\n",
    "        [cluster==x]) for x in range(num_clus)], axis=0))\n",
    "    average_distance.append(tmp_average_distance)\n",
    "    \n",
    "    \n",
    "# Plot the result -> Elbow point\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "ax.plot(range(1, max_num_clusters +1), np.mean(average_distance, axis=0))\n",
    "ax.set_xlim([1, max_num_clusters])\n",
    "ax.set_xlabel('number of clusters', fontsize=20)\n",
    "ax.set_ylabel('average inter cluster distance', fontsize=20)\n",
    "ax.set_title('Elbow point', fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*McSBHbOKIutNNhNbtWjQzQ.png\"></img>\n",
    "https://cdn-images-1.medium.com/max/1600/1*McSBHbOKIutNNhNbtWjQzQ.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see as well is that when we reach six clusters the average distance to the cluster center does not change much anymore. This is called the Elbow point and gives us a recommendation of how many clusters to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/clustering-electricity-profiles-with-k-means-42d6d0644d00\n",
    "<br>\n",
    "We take the average of the silhouette across all load-profiles in order to have a global view of how the algorithm is performing.\n",
    "I experiment with a range of cluster numbers (from 2 to 30). It is important to scale each period within the same range so that the magnitude of the energy load does not interfere in the selection of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "sillhoute_scores = []\n",
    "n_cluster_list = np.arange(2,31).astype(int)\n",
    "\n",
    "X = df_uci_pivot.values.copy()\n",
    "    \n",
    "# Very important to scale!\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "for n_cluster in n_cluster_list:\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_cluster)\n",
    "    cluster_found = kmeans.fit_predict(X)\n",
    "    sillhoute_scores.append(silhouette_score(X, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*9QNrTFc93ZXAHdcH2bX8MA.png\"></img>\n",
    "https://cdn-images-1.medium.com/max/1600/1*9QNrTFc93ZXAHdcH2bX8MA.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum average silhouette occurs when there are only 2 clusters, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>How many clusters?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few methods available to choose the optimal number of K. <br>\n",
    "\n",
    "The direct method is to just plot the datapoints and see if it gives you a hint.<br>\n",
    "Other method is to use the value of inertia, The idea behind good clustering is having a small value of inertia, and small number of clusters.<br>\n",
    "The value of inertia decreases as the number of clusters increase. So, its a trade-off here. Rule of thumb: The elbow point in the inertia graph is a good choice because after that the change in the value of inertia isn’t significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*xOGY4uu6ng7E8lPLP-onWw.png\"></img>\n",
    "https://cdn-images-1.medium.com/max/1600/1*xOGY4uu6ng7E8lPLP-onWw.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Final Note</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s important to preprocess your data before performing K-Means. You would have to convert your dataset into numerical values if it is not already.<br>\n",
    "Also, applying feature reduction techniques would speed up the process, and also improve the results.<br>\n",
    "<b>These steps are important to follow because K-Means is sensitive to outliers,</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>just like every other algo that uses average/mean values. Following these steps alleviate these issues.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Practive sample for tarining :</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Clustering electricity usage profiles with K-means</b><br>\n",
    "https://towardsdatascience.com/clustering-electricity-profiles-with-k-means-42d6d0644d00\n",
    "\n",
    "<br><b></b><br>\n",
    "\n",
    "\n",
    "<br><b></b><br>\n",
    "\n",
    "<br><b></b><br>\n",
    "\n",
    "<br><b></b><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
